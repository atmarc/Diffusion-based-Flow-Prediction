{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch.nn.utils import prune\n",
    "import zipfile\n",
    "from airfoil_diffusion.airfoil_datasets import *\n",
    "from airfoil_diffusion.networks import *\n",
    "from airfoil_diffusion.trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data:  23%|██▎       | 29/125 [00:00<00:00, 282.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 125/125 [00:00<00:00, 293.81it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./datasets/1_parameter/data/\"):\n",
    "    files=[file for file in os.listdir(\"./datasets/1_parameter/\") if file.endswith(\".zip\")]\n",
    "    for file in tqdm(files): \n",
    "        f=zipfile.ZipFile(\"./datasets/1_parameter/\"+file,'r')\n",
    "        for file in f.namelist():\n",
    "            f.extract(file,\"./datasets/1_parameter/data/\")\n",
    "        f.close() \n",
    "\n",
    "train_dataset = AirfoilDataset(FileDataFiles(\"./datasets/1_parameter/train_cases.txt\",base_path=\"./datasets/1_parameter/data/\"),\n",
    "                               data_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_configs = {\n",
    "    \"attention_layers\": [2, 3],\n",
    "    \"condition_layers\": [-2],\n",
    "    \"depth_each_layer\": 2,\n",
    "    \"dim_basic\": 16,\n",
    "    \"dim_condition\": 3,\n",
    "    \"dim_encoded_time\": 8,\n",
    "    \"dim_in\": 3,\n",
    "    # \"dim_multipliers\": [1, 2, 4, 4],\n",
    "    \"dim_multipliers\": [2, 2, 2, 2],\n",
    "    \"dim_out\": 3,\n",
    "    \"heads_attention\": 4,\n",
    "    \"linear_attention\": False,\n",
    "    \"skip_connection_scale\": 0.707,\n",
    "    \"use_input_condition\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_layers: [2, 3]\n",
      "condition_layers: [-2]\n",
      "depth_each_layer: 2\n",
      "dim_basic: 16\n",
      "dim_condition: 3\n",
      "dim_encoded_time: 8\n",
      "dim_in: 6\n",
      "dim_multipliers: [2, 2, 2, 2]\n",
      "dim_out: 3\n",
      "heads_attention: 4\n",
      "linear_attention: False\n",
      "skip_connection_scale: 0.707\n",
      "use_input_condition: True\n",
      "condition_dim: 0\n"
     ]
    }
   ],
   "source": [
    "network = AifNet(**network_configs)\n",
    "network.show_current_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_trainer = DiffusionTrainer()\n",
    "train_configs = {\n",
    "    \"name\": \"training\",\n",
    "    \"save_path\": \"./training/single_parameter/32/\",\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"batch_size_train\": len(train_dataset),\n",
    "    \"shuffle_train\": True,\n",
    "    \"num_workers_train\": 0,\n",
    "    \"validation_epoch_frequency\": 0,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"lr_scheduler\": \"step\",\n",
    "    \"warmup_epoch\": 0,\n",
    "    \"record_iteration_loss\": False,\n",
    "    \"epochs\": 125000,\n",
    "    \"save_epoch\": 5000,\n",
    "    \"lr\": 0.0001,\n",
    "    \"final_lr\": 0.00001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_trainer.train_from_scratch(network, train_dataset, **train_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sparcity(model):\n",
    "    total_params = 0\n",
    "    total_zeros = 0\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if hasattr(module, \"weight\"):\n",
    "            num_params = sum(p.numel() for p in module.parameters())\n",
    "            total_params += num_params\n",
    "            total_zeros += torch.sum(module.weight == 0)\n",
    "\n",
    "    return total_params, total_zeros.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prune(network: nn.Module, prune_type:str, pruning_percentage:float):\n",
    "    norm_n = {'L1': 1, 'L2': 2}[prune_type]\n",
    "\n",
    "    for module in network.modules():\n",
    "        if type(module) is nn.Conv2d and module.out_channels > 3:\n",
    "            prune.ln_structured(module, 'weight', amount=pruning_percentage, dim=0, n=norm_n)\n",
    "\n",
    "\n",
    "def prune_remove(network):\n",
    "    for module in network.modules():\n",
    "        if type(module) is nn.Conv2d and module.out_channels > 3:\n",
    "            prune.remove(module, 'weight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426194, 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = AifNet(**network_configs)\n",
    "evaluate_sparcity(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_prune(network, \"L1\", 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sparse: 44.73%'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_w, n_zeros = evaluate_sparcity(network)\n",
    "f\"Sparse: {100 * n_zeros / total_w:.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5132188731375618"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.92**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(8):\n",
    "    _prune(network, \"L1\", (1 - 0.92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sparse: 44.24%'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_w, n_zeros = evaluate_sparcity(network)\n",
    "f\"Sparse: {100 * n_zeros / total_w:.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
